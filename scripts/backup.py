import os
import json
import base64
import requests
import gspread
from datetime import datetime, timezone
from oauth2client.service_account import ServiceAccountCredentials

# ======= è°ƒè¯•ä¿¡æ¯ï¼šæ‰“å°ç¯å¢ƒå˜é‡å…³é”®å€¼ =======
print("\n=== Debug Info: Environment Variables ===")
print(f"SUPABASE_URL: {os.environ.get('SUPABASE_URL')}")
print(f"SPREADSHEET_ID: {os.environ.get('SPREADSHEET_ID')}")
print(f"GCP_SHEET_CRED length: {len(os.environ.get('GCP_SHEET_CRED', ''))}")
print("==========================================\n")

# 1. Google Sheets API æˆæƒ
cred_str = os.environ['GCP_SHEET_CRED']
cred_dict = json.loads(base64.b64decode(cred_str))
scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']
creds = ServiceAccountCredentials.from_json_keyfile_dict(cred_dict, scope)
gc = gspread.authorize(creds)
sheet = gc.open_by_key(os.environ['SPREADSHEET_ID'])

# Supabase å‚æ•°
SUPABASE_URL = os.environ['SUPABASE_URL']
SUPABASE_KEY = os.environ['SUPABASE_API_KEY']
headers = {
    "apikey": SUPABASE_KEY,
    "Authorization": f"Bearer {SUPABASE_KEY}",
    "Content-Type": "application/json"
}

# æ‹‰å–æ‰€æœ‰è¡¨å
tables = requests.post(f"{SUPABASE_URL}/rest/v1/rpc/get_all_user_tables", headers=headers).json()
print(f"ğŸ“‹ Tables found: {tables}\n")

for table in tables:
    print(f"ğŸ”„ Backing up table: {table}")
    worksheet_name = table

    # è·å–æˆ–æ–°å»º worksheet
    try:
        ws = sheet.worksheet(worksheet_name)
    except gspread.exceptions.WorksheetNotFound:
        ws = sheet.add_worksheet(title=worksheet_name, rows="1000", cols="20")
        ws.append_row(["id", "note", "updated_at"])

    # è¯»å–å·²æœ‰æ•°æ®ï¼Œæ‰¾æœ€åä¸€ä¸ª updated_at
    records = ws.get_all_values()
    last_updated = "1970-01-01T00:00:00Z"
    if len(records) > 1:
        try:
            raw_ts = records[-1][-1].strip()
            dt = datetime.fromisoformat(raw_ts.replace("Z", "+00:00")).astimezone(timezone.utc)
            last_updated = dt.strftime("%Y-%m-%dT%H:%M:%S.%fZ")
        except Exception as e:
            print(f"âš ï¸ Warning parsing timestamp: {e}")

    print(f"   â¡ Last updated timestamp used for {table}: {last_updated}")

    # è¯·æ±‚å‚æ•°
    params = {
        "updated_at": f"gt.{last_updated}",
        "order": "updated_at.asc"
    }
    url = f"{SUPABASE_URL}/rest/v1/{table}"

    # ======= è°ƒè¯•ä¿¡æ¯ï¼šæ‰“å°è¯·æ±‚ç»†èŠ‚ =======
    print(f"   â¡ Request URL: {url}")
    print(f"   â¡ Request Params: {params}")
    print(f"   â¡ Request Headers (shortened): {{'apikey': '***', 'Authorization': 'Bearer ***'}}")

    resp = requests.get(url, headers=headers, params=params)

    print(f"   â¡ HTTP Status: {resp.status_code}")
    if resp.status_code != 200:
        print(f"âŒ Error fetching {table}: {resp.text}")
        continue

    new_data = resp.json()
    print(f"âœ… {len(new_data)} rows fetched from {table}")
    if new_data:
        print(f"   Sample row: {new_data[0]}")  # æ‰“å°ç¬¬ä¸€æ¡çœ‹çœ‹å®é™…å†…å®¹

        fields = list(new_data[0].keys())
        if len(records) <= 1:
            ws.update('A1', [fields])
        for row in new_data:
            values = [row.get(f, '') for f in fields]
            ws.append_row(values)

print("\n=== Backup Finished ===")
